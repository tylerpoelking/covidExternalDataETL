{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Integrate\n",
    "- Change directories where commented '#Change Dir'\n",
    "- Download new KFF State Data at 'https://www.kff.org/health-costs/issue-brief/state-data-and-policy-actions-to-address-coronavirus/' and drop and drop raw_data.csv to the corresponding directory (see State Actions section below)\n",
    "- Run Script around 5 pm EST, assure output below Final Output section corresponds to today's date. Example:\n",
    "**** COVID TRACKING DATE: 2020-04-21 00:00:00  ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions + Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import requests, zipfile, io\n",
    "#Change Dir\n",
    "BOX_PATH = '/Users/tyler.poelkingibm.com/Box Sync/Mondelez: Demand forecasts during COVID-19/4. EDA & Descriptive analytics'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabstate(string):\n",
    "    return states_daily[states_daily['state']==string]\n",
    "\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The COVID Tracking Project\n",
    "CovidActNow was created by a team of data scientists, engineers, and designers in partnership with epidemiologists, \n",
    "public health officials, and political leaders to help understand how the COVID-19 pandemic will affect \n",
    "their region\n",
    "\n",
    "Source: https://covidtracking.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_current = pd.read_csv('https://covidtracking.com/api/states.csv')\n",
    "states_daily = pd.read_csv('https://covidtracking.com/api/states/daily.csv', parse_dates=['date'])\n",
    "states_info = pd.read_csv('https://covidtracking.com/api/states/info.csv')\n",
    "US_current = pd.read_csv('https://covidtracking.com/api/us.csv')\n",
    "US_daily = pd.read_csv('https://covidtracking.com/api/us/daily.csv', parse_dates=['date'])\n",
    "\n",
    "#Hospital beds per 1,000 people. American Hospital Association Annual Survey (2018).\n",
    "beds  = pd.read_csv(f'{BOX_PATH}/Data/Static/State/hospital_beds.csv', header=2)\n",
    "beds = beds[beds['Location']!='United States']\n",
    "beds.columns = ['Location', 'Hospital_Beds_Per_1k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove uneeded states\n",
    "states_daily = states_daily[~states_daily['state'].isin([\"AS\",\"MP\",'GU','PR','VI'])]\n",
    "states_current = states_current[~states_current['state'].isin([\"AS\",\"MP\",'GU','PR','VI'])].drop(columns=['notes','hash'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort. Required.\n",
    "states_daily.sort_values(['state','date'], inplace = True, ascending=[True, True])\n",
    "US_daily.sort_values('date', inplace = True, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr_cols = ['positive', 'negative','hospitalized','death']\n",
    "stat_cols = ['positive', 'negative','pending','hospitalized','death']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logs (For Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in stat_cols:\n",
    "    states_daily[f'{col}_log'] = np.log(states_daily[col]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in incr_cols:\n",
    "    states_daily.rename(columns={f'{col}Increase':f'daily {col}'}, inplace=True)\n",
    "    US_daily.rename(columns={f'{col}Increase':f'daily {col}'}, inplace=True)\n",
    "    \n",
    "states_daily.rename(columns={'totalTestResultsIncrease':'daily total'}, inplace=True)\n",
    "US_daily.rename(columns={'totalTestResultsIncrease':'daily total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in stat_cols:\n",
    "    states_daily[f'{col}_pct_chg'] = (states_daily.groupby('state')[col].apply(pd.Series.pct_change))\n",
    "    US_daily[f'{col}_pct_chg'] = US_daily[col].pct_change()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Percent Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [int(3),int(5)]\n",
    "for window in windows:\n",
    "    for col in stat_cols:\n",
    "        states_daily[f'{col}_{window}_day_avg_pct_chg'] = states_daily.groupby('state')[f'{col}_pct_chg'].rolling(window).mean().reset_index(0,drop=True)\n",
    "        US_daily[f'{col}_{window}_day_avg_pct_chg'] = US_daily[f'{col}_pct_chg'].rolling(window).mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days since first instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = states_daily.copy()\n",
    "tmp=tmp[tmp.groupby('state')['positive'].cumsum().gt(0)]\n",
    "tmp['days_since_first_pos'] = tmp.groupby('state').cumcount()\n",
    "states_daily=states_daily.merge(tmp['days_since_first_pos'], how='left', right_index=True,left_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean + Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_daily.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "US_daily.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_cols_simple = ['date', 'state', 'positive', 'negative', 'pending', 'hospitalized',\n",
    "       'death', 'dateChecked', 'daily positive',\n",
    "       'daily negative','daily hospitalized',\n",
    "       'daily death', 'positive_pct_chg',\n",
    "       'negative_pct_chg', 'pending_pct_chg', 'hospitalized_pct_chg',\n",
    "       'death_pct_chg']\n",
    "\n",
    "US_cols_simple = ['date', 'states', 'positive', 'negative', 'pending', 'hospitalized',\n",
    "       'death', 'daily positive',\n",
    "       'daily negative', 'daily hospitalized',\n",
    "       'daily death', 'positive_pct_chg',\n",
    "       'negative_pct_chg', 'pending_pct_chg', 'hospitalized_pct_chg',\n",
    "       'death_pct_chg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_current.to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/states_current.csv', index=False)\n",
    "states_daily[states_cols_simple].to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/states_daily.csv', index=False)\n",
    "states_daily.to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/states_daily_all.csv', index=False)\n",
    "states_info.to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/states_info.csv', index=False)\n",
    "US_current.to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/US_current.csv', index=False)\n",
    "US_daily[US_cols_simple].to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/US_daily.csv', index=False)\n",
    "US_daily.to_csv(f'{BOX_PATH}/Data/Corona/COVID Tracking Project/US_daily_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State level\n",
    "Data USA puts public US Government data in your hands. Instead of searching through multiple data sources that are often incomplete and difficult to access, you can simply point to Data USA to answer your questions\n",
    "\n",
    "Source: https://datausa.io/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dir = f'{BOX_PATH}/Data/State'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_state_static = pd.DataFrame()\n",
    "mini_state_static_list = []\n",
    "for filename in os.listdir(box_dir):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        print(f'Aggregating {filename}')\n",
    "        min_state_static = pd.read_csv(f'{box_dir}/{filename}')\n",
    "        min_state_static['Geography']=min_state_static['Geography'].str.strip()\n",
    "        min_state_static.sort_values('Year', inplace=True, ascending = True)\n",
    "        for col in [col for col in min_state_static.columns if col not in ['Year','Geography','ID Geography']]:\n",
    "            min_state_static[col] = min_state_static.groupby('Geography')[col].fillna(method='ffill')\n",
    "        min_state_static.drop_duplicates(subset=['Geography'], keep='last', inplace=True)\n",
    "        assert ((min_state_static['Geography'].value_counts()>1).mean())==0\n",
    "        min_state_static.set_index('Geography', inplace=True)\n",
    "        mini_state_static_list.append(min_state_static)\n",
    "        \n",
    "        \n",
    "full_state_static = pd.concat(mini_state_static_list, axis=1,copy=False).reset_index().rename(columns={'index':'Geography'})\n",
    "full_state_static = full_state_static[~full_state_static['Geography'].isin(['Puerto Rico','American Samoa', 'Federated States of Micronesia','Marshall Islands', 'Commonwealth of the Northern Mariana Islands','Palau','United States Virgin Islands','Guam'])]\n",
    "full_state_static = full_state_static.loc[:,~full_state_static.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add state initial feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "full_state_static['State Initial'] = full_state_static['Geography'].replace(us_state_abbrev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine COVID data with State Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_daily = states_daily.merge(full_state_static, left_on='state', right_on='State Initial', how='left', validate='m:1')\n",
    "states_daily = states_daily.merge(beds, left_on='Geography', right_on='Location', how='left', validate='m:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (states_daily['Geography'].nunique() ==51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Dir\n",
    "states_daily.to_csv(f'{BOX_PATH}/Data/Combined/states_covid_daily_w_demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Actions\n",
    "\n",
    "Source (State Actions to Mitigate the Spread of COVID-19): https://www.kff.org/health-costs/issue-brief/state-data-and-policy-actions-to-address-coronavirus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add your directory where you wish to store the latest version of KFF State Actions\n",
    "\n",
    "#This will error it a file was not uploaded/modified today. If so, grab file from KFF and upload in dir\n",
    "date_modified = ! cd Data/State/Actions/new/ && GetFileInfo -d raw_data.csv\n",
    "print(f'**** Latest KFF State Action File modified on {date_modified} ****')\n",
    "assert(pd.Timestamp(date_modified[0]).floor(\"D\") == pd.Timestamp.today().floor(freq='D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Dir\n",
    "box_dir = f'{BOX_PATH}/Data/State'\n",
    "#TODO: Add your directory where you wish to store the latest version of KFF State Actions\n",
    "#Change Dir\n",
    "local_dir = 'Data/State/Actions/new'\n",
    "\n",
    "#Load historical actions\n",
    "\n",
    "ta_h = pd.read_csv(f'{box_dir}/Actions/historical/state_actions_historical.csv', parse_dates=['date'])\n",
    "#Remove today if there (for repopulating)\n",
    "ta_h = ta_h[ta_h['date'].dt.date != pd.Timestamp.today()]\n",
    "\n",
    "#Load new actions\n",
    "ta = pd.read_csv(f'{local_dir}/raw_data.csv',header=2)\n",
    "\n",
    "\n",
    "#Process Data\n",
    "ta.drop(['Footnotes','Primary Election Postponement'], axis=1,inplace=True)\n",
    "ta.dropna(inplace=True)\n",
    "ta.replace('-', 'None', inplace=True)\n",
    "ta=ta[ta['Location']!='United States']\n",
    "ta['date'] = pd.Timestamp.today().floor(freq='D')\n",
    "ta.rename(columns={'Location':'Geography','School Closures': 'State-Mandated School Closures'},inplace=True)\n",
    "\n",
    "\n",
    "#Sort columns and assert they are the same (checks for site changes to column names)\n",
    "ta = ta.reindex(sorted(ta.columns), axis=1)\n",
    "ta_h = ta_h.reindex(sorted(ta_h.columns), axis=1)\n",
    "assert(len(ta)==51)\n",
    "assert(all([i[0]==i[1] for i in list(zip(ta.columns,ta_h.columns))])), [i for i in list(zip(ta.columns,ta_h.columns))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i[0]==i[1] for i in list(zip(ta.columns,ta_h.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_h.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append new day's data to historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action columns we will use to create calculated columns\n",
    "#Add new as needed here\n",
    "action_cols = ['State Is Easing Social Distancing Measures','Bar/Restaurant Limits',\n",
    " 'Emergency Declaration',\n",
    " 'Large Gatherings Ban',\n",
    " 'Stay at Home Order',\n",
    "'Mandatory Quarantine for Travelers',\n",
    " 'Non-Essential Business Closures',\n",
    " 'State-Mandated School Closures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_total = pd.concat([ta_h,ta], axis=0)\n",
    "\n",
    "for col in action_cols:\n",
    "    ta_total[col] = ta_total[col].str.replace(\"*\", \"\")\n",
    "\n",
    "ta_total.sort_values(['Geography','date'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of days each state has implimented each action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in action_cols:\n",
    "    ta_total[f'days_on_{col}_status'] = ta_total.groupby(['Geography',col]).cumcount()+1\n",
    "    ta_total.loc[ta_total[col].isna(), f'days_on_{col}_status']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Action Indicated Column Given Threshold Number of Days Implimented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = (pd.Timestamp.today().floor(freq='D'))\n",
    "thresh = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new as needed here\n",
    "ta_total.loc[(ta_total['date']==today) & (\n",
    "    (ta_total['days_on_State Is Easing Social Distancing Measures_status']==thresh)|\n",
    "    (ta_total['days_on_Bar/Restaurant Limits_status']==thresh)|                                                                 \n",
    "    (ta_total['days_on_Emergency Declaration_status']==thresh)|\n",
    "    (ta_total['days_on_Large Gatherings Ban_status']==thresh)|\n",
    "    (ta_total['days_on_Stay at Home Order_status']==thresh)|\n",
    "    (ta_total['days_on_Mandatory Quarantine for Travelers_status']==thresh)|\n",
    "    (ta_total['days_on_Non-Essential Business Closures_status']==thresh)|\n",
    "    (ta_total['days_on_State-Mandated School Closures_status']==thresh)), 'new_state_action'] = 1\n",
    "\n",
    "ta_total['new_state_action'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Action Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new as needed herev\n",
    "ta_total.loc[(ta_total['date']==today) &(ta_total['days_on_State Is Easing Social Distancing Measures_status']==1), 'new_state_action_easing_social_dist_measures'] = 1\n",
    "ta_total.loc[(ta_total['date']==today) &(ta_total['days_on_Non-Essential Business Closures_status']==1), 'new_state_action_NEB_closures'] = 1\n",
    "ta_total.loc[(ta_total['date']==today) &(ta_total['days_on_Bar/Restaurant Limits_status']==1), 'new_state_action_restaurant_limits'] = 1\n",
    "ta_total.loc[(ta_total['date']==today) &(ta_total['days_on_Emergency Declaration_status']==1), 'new_state_action_emergency'] = 1\n",
    "ta_total.loc[(ta_total['date']==today) &(ta_total['days_on_Stay at Home Order_status']==1), 'new_state_action_stay_at_home'] = 1\n",
    "\n",
    "#Add new as needed here\n",
    "ta_total['new_state_action_easing_social_dist_measures'].fillna(0, inplace=True)\n",
    "ta_total['new_state_action_NEB_closures'].fillna(0, inplace=True)\n",
    "ta_total['new_state_action_restaurant_limits'].fillna(0, inplace=True)\n",
    "ta_total['new_state_action'].fillna(0, inplace=True)\n",
    "ta_total['new_state_action_emergency'].fillna(0, inplace=True)\n",
    "ta_total['new_state_action_stay_at_home'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative unique actions\n",
    "#Add new as needed here\n",
    "ta_total['easing_social_dist_measures_changecount'] = ta_total.groupby('Geography')['new_state_action_easing_social_dist_measures'].cumsum()\n",
    "ta_total['neb_closures_changecount'] = ta_total.groupby('Geography')['new_state_action_NEB_closures'].cumsum()\n",
    "ta_total['restaurant_limits_changecount'] = ta_total.groupby('Geography')['new_state_action_restaurant_limits'].cumsum()\n",
    "ta_total['state_emergency_changecount'] = ta_total.groupby('Geography')['new_state_action_emergency'].cumsum()\n",
    "ta_total['stay_at_home_changecount'] = ta_total.groupby('Geography')['new_state_action_stay_at_home'].cumsum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ['State Is Easing Social Distancing Measures','Bar/Restaurant Limits',\n",
    "#  'Emergency Declaration',\n",
    "#  'Large Gatherings Ban',\n",
    "#  'Stay at Home Order',\n",
    "# 'Mandatory Quarantine for Travelers',\n",
    "#  'Non-Essential Business Closures',\n",
    "#  'State-Mandated School Closures']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_daily = states_daily.merge(ta_total, on=['date','Geography'], how='left', validate='1:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent State Actions (Reformatted Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State\tDate\tAction \tDay Difference\n",
    "(Most Recent Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ta_total.copy()\n",
    "#Can Remove\n",
    "test = test[~((test['State Is Easing Social Distancing Measures']==1)&(test['Stay at Home Order']==\"None\"))]\n",
    "\n",
    "days_cols = [col for col in ta_total.columns if 'days_' in col]\n",
    "first_action_day_tracker_sub = test[['Geography','date']+days_cols]\n",
    "first_action_day_tracker = pd.wide_to_long(first_action_day_tracker_sub, stubnames = 'days_on',suffix='\\\\D+', i=[\"Geography\",'date'], j='Recent Status Changed').reset_index()\n",
    "first_action_day_tracker['Recent Status Changed'] = first_action_day_tracker['Recent Status Changed'].str.replace('_', ' ')\n",
    "first_action_day_tracker_fin = first_action_day_tracker.merge(ta_total[['Geography','date','Bar/Restaurant Limits','Mandatory Quarantine for Travelers','Emergency Declaration','Large Gatherings Ban','Stay at Home Order','Non-Essential Business Closures','State-Mandated School Closures']], on=['Geography','date'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_action_day_tracker_fin['State'] = first_action_day_tracker_fin['Geography'].replace(us_state_abbrev)\n",
    "first_action_day_tracker_fin[first_action_day_tracker_fin['days_on']==1].to_csv(f'{BOX_PATH}/Data/State/Actions/first_day_action_tracker.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_date = ta_total.drop_duplicates(subset=['Geography'], keep='last')\n",
    "days_cols = [col for col in ta_total.columns if 'days_' in col]\n",
    "curr_date_sub = curr_date[['Geography']+days_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.wide_to_long(curr_date_sub, stubnames = 'days_on',suffix='\\\\D+', i=\"Geography\", j='Recent Status Changed').reset_index()\n",
    "l['Recent Status Changed'] = l['Recent Status Changed'].str.replace('_', ' ')\n",
    "l = l.merge(curr_date[['Geography','State Is Easing Social Distancing Measures','Bar/Restaurant Limits','Mandatory Quarantine for Travelers','Emergency Declaration','Large Gatherings Ban','Stay at Home Order','Non-Essential Business Closures','State-Mandated School Closures']], on='Geography', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_action (row):\n",
    "    val = row['Recent Status Changed'].replace(' status','')\n",
    "    val = val.strip()\n",
    "    #print(val)\n",
    "    return row[val]\n",
    "\n",
    "l['Action']=l.apply(lambda row: label_action(row), axis=1)\n",
    "l = l[['Geography', 'Recent Status Changed', 'days_on', 'Action']]\n",
    "l.rename(columns={'days_on':'Days Since Change'},inplace=True)\n",
    "l['State'] = l['Geography'].replace(us_state_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_date (row):\n",
    "    val = pd.Timestamp.today().floor(freq='D')-pd.Timedelta(days = (row['Days Since Change']-1))\n",
    "    \n",
    "    return val\n",
    "\n",
    "l['Date Implemented On']=l.apply(lambda row: label_date(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.sort_values('Days Since Change',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to only rows where Days Since Change = mininum(Days Since Change) for each state \n",
    "#(accounts for if there are two changes in a day)\n",
    "\n",
    "l = l[l['Days Since Change'] == l.groupby('Geography')['Days Since Change'].transform('min')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter on recent days only\n",
    "l = l[l['Days Since Change']<=31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.sort_values('Days Since Change',inplace=True)#].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projections\n",
    "\n",
    "Source: http://www.healthdata.org/covid/data-downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download file from https://covid19.healthdata.org/projections as zip. Extract to Local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip\n",
    "r = requests.get('https://ihmecovid19storage.blob.core.windows.net/latest/ihme-covid19.zip', stream=True)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(path='Data/Projections')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Latest File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get earliest file in Projections\n",
    "projections_dir = 'Data/Projections/*'\n",
    "list_of_files = glob.glob(projections_dir)\n",
    "new_proj_file = max(list_of_files, key=os.path.getctime) + '/*.csv'\n",
    "proj_path = glob.glob(new_proj_file)\n",
    "assert(len(proj_path)==1), 'MORE THAN ONE PROJECTIONS CSV'\n",
    "PROJ_STATUS = f'READ IHME PROJECTIONS FILE AT: {proj_path[0]}'\n",
    "    \n",
    "proj_path = proj_path[0]\n",
    "projections = pd.read_csv(proj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Processing of Latest Projection File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing\n",
    "date_cols = [col for col in projections.columns if 'date' in col]\n",
    "assert(len(date_cols)==1)\n",
    "projections[date_cols[0]] = pd.to_datetime(projections[date_cols[0]], infer_datetime_format=True)\n",
    "\n",
    "projections.rename(columns={'location_name':'Geography',date_cols[0]:'date'},inplace=True)\n",
    "\n",
    "#filter to just geographies in states_daily\n",
    "geos = set(states_daily['Geography'])\n",
    "geos.add('United States of America')\n",
    "projections=projections[projections['Geography'].isin(geos)]\n",
    "assert(52 == len(set(projections['Geography'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join state static data \n",
    "og_len = len(projections)\n",
    "projections = projections.merge(states_daily, on=['date','Geography'], how='left', validate='1:1')\n",
    "projections.loc[projections['Geography']=='United States of America', 'Total Population']= 331002651\n",
    "\n",
    "#Fill static date columns that did not have a corresponding match from COVID tracking data (unmatched dates)\n",
    "for col in full_state_static.columns:\n",
    "    projections[col] = projections.groupby('Geography')[col].fillna(method='ffill')\n",
    "    projections[col] = projections.groupby('Geography')[col].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(~projections['Total Population'].hasnans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New calculated columns \n",
    "\n",
    "death_rate = 1\n",
    "projections['new_pop_affected'] = projections['deaths_mean'] *100 / death_rate\n",
    "projections['total_pop_affected'] = projections['totdea_mean'] *100 / death_rate\n",
    "\n",
    "#Shift 14 days for lag time between getting COVID and dying\n",
    "projections['total_pop_affected'] = projections.groupby('Geography')['total_pop_affected'].shift(-14)\n",
    "projections['new_pop_affected'] = projections.groupby('Geography')['new_pop_affected'].shift(-14)\n",
    "\n",
    "#Percent population affected\n",
    "projections['perc_population_affected']=projections['total_pop_affected']/projections['Total Population']\n",
    "\n",
    "#Threshold for lockdown openings based on 0.5% new cases growth rate WHO (https://www.aljazeera.com/news/2020/04/italy-remain-lockdown-3-200410232013521.html)\n",
    "projections[f'affected_pct_chg'] = 100*(projections.groupby('Geography')['total_pop_affected'].apply(pd.Series.pct_change))\n",
    "projections[f'affected_pct_chg'].replace([np.inf,-np.inf], 0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(~projections['Total Population'].hasnans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate and Remap Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (og_len == len(projections))\n",
    "projections['State'] = projections['Geography'].replace(us_state_abbrev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketing States By Projections Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = projections[projections['Geography']!='Life Care Center, Kirkland, WA']\n",
    "\n",
    "peak_deaths = pd.DataFrame()\n",
    "#.3 = 30%\n",
    "thresh = .3\n",
    "\n",
    "for geo in geos:\n",
    "\n",
    "    # filter to one geo\n",
    "    state_df = projections[projections['Geography']==geo]\n",
    "    \n",
    "    #get the max deaths/day stat\n",
    "    max_deaths = state_df['deaths_mean'].max()\n",
    "\n",
    "    #calculate threshold deaths_mean \n",
    "    thresh_percentile_death_rate = state_df[state_df['deaths_mean']>0]['deaths_mean'].quantile(thresh)\n",
    "\n",
    "    #get date of peak. if multiple peaks get latest date one\n",
    "    max_day_geo = state_df[state_df['deaths_mean']==max_deaths].drop_duplicates(subset=['Geography'], keep='last')\n",
    "    max_day = max_day_geo['date'].values[0]\n",
    "\n",
    "    #Start date\n",
    "    #Get subset of state projections where deaths/day GREATER than or equal to threshold on the LEFT side of the 'bell curve' \n",
    "    start = state_df[(state_df['deaths_mean']>=thresh_percentile_death_rate)&(state_df['date']<max_day)]\n",
    "    #calc max date of subset above\n",
    "    start_day = min(start['date'])\n",
    "\n",
    "\n",
    "    #End Date\n",
    "    # Get subset of state projections where deaths/day GREATER than or equal to threshold on the RIGHT side of the 'bell curve'\n",
    "    end = state_df[(state_df['deaths_mean']>=thresh_percentile_death_rate)&(state_df['date']>max_day)]\n",
    "    #calc min date of subset above\n",
    "    end_day = max(end['date'])\n",
    "    \n",
    "    #Lockdown removal threshold\n",
    "    lockdown_remove = state_df[(state_df['affected_pct_chg']<0.1)&(state_df['date']>max_day)]\n",
    "    lockdown_remove_day = min(lockdown_remove['date'])\n",
    "    \n",
    "\n",
    "    #get cumulative deaths at that point\n",
    "    end_death_cum = state_df[state_df['date']==end_day]['totdea_mean'].values[0]\n",
    "\n",
    "    #Add columns\n",
    "    start_day = pd.Timestamp(start_day)\n",
    "    end_day = pd.Timestamp(end_day)\n",
    "    max_day_geo['start_day'] = start_day\n",
    "    max_day_geo['end_day'] = end_day\n",
    "    max_day_geo['lockdown_removal_day'] = lockdown_remove_day\n",
    "    max_day_geo['end_totdea_mean'] = end_death_cum\n",
    "    max_day_geo['thresh_perc_dea'] = thresh_percentile_death_rate\n",
    "\n",
    "    #Append\n",
    "    peak_deaths = peak_deaths.append(max_day_geo, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_deaths.rename(columns={'date':'peak_deaths_date','deaths_mean':'peak_deaths_mean','totdea_mean':'peak_totdea_mean'},inplace=True)\n",
    "peak_deaths = peak_deaths[['Geography','start_day','peak_deaths_date','peak_deaths_mean','peak_totdea_mean','end_day','end_totdea_mean','thresh_perc_dea','lockdown_removal_day','Total Population']]\n",
    "\n",
    "#Merge other data to peak deaths\n",
    "peak_deaths = peak_deaths.merge(full_state_static[['Geography','State Initial']], on=['Geography'], how='left')\n",
    "peak_deaths.rename(columns={'State Initial':'state'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculated Fields\n",
    "peak_deaths['peak_affected_date'] = peak_deaths['peak_deaths_date']-pd.Timedelta(days=14)\n",
    "peak_deaths['perc_deaths_at_peak'] = np.round((100*(peak_deaths['peak_totdea_mean']/peak_deaths['Total Population'])),2)\n",
    "peak_deaths['perc_deaths_at_end']=np.round((100*(peak_deaths['end_totdea_mean']/peak_deaths['Total Population'])),2)\n",
    "peak_deaths['days_start_to_end']=(peak_deaths['end_day']-peak_deaths['start_day']).dt.days\n",
    "#Add deaths per million (end_totdea_mean/(total population/1,000,000))\n",
    "peak_deaths['total_deaths_at_end_per_million'] = peak_deaths['end_totdea_mean']/(peak_deaths['Total Population']/1000000)\n",
    "peak_deaths['days_until_peak']=(peak_deaths['peak_deaths_date']-pd.Timestamp.today()).dt.days\n",
    "peak_deaths['days_until_end']=(peak_deaths['end_day']-pd.Timestamp.today()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_deaths.to_csv(f'{BOX_PATH}/Data/Projections/peak_deaths.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_deaths['days_start_to_end'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Solidify\n",
    "peak_deaths.loc[(peak_deaths['perc_deaths_at_end']>.03)&(peak_deaths['days_start_to_end']<=60),'state_segment'] = 1\n",
    "peak_deaths.loc[(peak_deaths['perc_deaths_at_end']>.02)&(peak_deaths['state_segment']!=1)&(peak_deaths['days_start_to_end']<=84),'state_segment'] = 2\n",
    "\n",
    "peak_deaths.loc[peak_deaths['peak_deaths_mean']<=10,'state_segment'] = 4\n",
    "peak_deaths['state_segment'].fillna(3, inplace=True)\n",
    "peak_deaths = peak_deaths[(peak_deaths['days_start_to_end'].notna())&(peak_deaths['perc_deaths_at_end'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add segments to states_daily\n",
    "og_len = len(states_daily)\n",
    "states_daily = states_daily.merge(peak_deaths[['Geography','state_segment','days_start_to_end','end_totdea_mean','total_deaths_at_end_per_million']],on='Geography',how='left',validate='m:1')\n",
    "assert(og_len==len(states_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add segments to projections\n",
    "og_len = len(projections)\n",
    "projections = projections.merge(peak_deaths[['Geography','state_segment','start_day','end_day','days_start_to_end','end_totdea_mean','total_deaths_at_end_per_million','thresh_perc_dea','peak_deaths_mean','peak_deaths_date','peak_affected_date']],on='Geography',how='left',validate='m:1')\n",
    "assert(og_len==len(projections))\n",
    "projections['peak_deaths_date'] = projections.groupby('Geography')['peak_deaths_date'].fillna(method='ffill')\n",
    "projections['peak_deaths_date'] = projections.groupby('Geography')['peak_deaths_date'].fillna(method='bfill')\n",
    "projections['days_until_peak']=(projections['peak_deaths_date']-projections['date']).dt.days\n",
    "\n",
    "\n",
    "#KEEP Results Checks\n",
    "#print(peak_deaths['state_segment'].value_counts())\n",
    "#print(peak_deaths[peak_deaths['Geography']!='Maine'].groupby('state_segment')['perc_deaths_at_end'].mean())\n",
    "#peak_deaths[['state_segment','Geography','days_start_to_end','perc_deaths_at_end','totdea_mean']].sort_values(['state_segment','totdea_mean'], ascending = [True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_daily['date'].max().floor(freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert states_daily['Geography'].nunique()==51\n",
    "\n",
    "#Check COVID Tracking updated with todays? date (will only work past 4pm based on site)\n",
    "print(PROJ_STATUS)\n",
    "print('**** COVID TRACKING DATE:', states_daily['date'].max().floor(freq='D'), ' ****')\n",
    "#assert((pd.Timestamp.today()).floor(\"D\") == states_daily['date'].max().floor(freq='D'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: KMeans For Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "health_cols = ['days_start_to_end','days_until_peak','perc_deaths_at_end']\n",
    "\n",
    "X = peak_deaths[health_cols]\n",
    "\n",
    "#X.dropna(how='any',inplace=True)\n",
    "print(len(X))\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X= scaler.fit_transform(X)\n",
    "\n",
    "X\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 20):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 20), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "peak_deaths['bucket']=pred_y\n",
    "\n",
    "\n",
    "print('States In Each Bucket:')\n",
    "print(peak_deaths['bucket'].value_counts())\n",
    "print()\n",
    "for col in health_cols:\n",
    "    print(col)\n",
    "    print(peak_deaths.groupby('bucket')[col].mean())\n",
    "    print()\n",
    "    #print(peak_deaths[peak_deaths['Geography']!='Maine'].groupby('bucket')[col].mean())\n",
    "\n",
    "peak_deaths[['bucket','Geography','peak_totdea_mean']+health_cols].sort_values(['bucket','peak_totdea_mean'], ascending = [True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Backups To Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change Dir\n",
    "ta_total.to_csv(f'{BOX_PATH}/Data/backups/state_actions_bu_{str(pd.Timestamp.today()).replace(\"-\",\"_\")}.csv')\n",
    "states_daily.to_csv(f'{BOX_PATH}/Data/backups/states_daily_bu_{str(pd.Timestamp.today()).replace(\"-\",\"_\")}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Write All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_daily.drop(['Year','ID Geography','hash','fips','Location','state'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_daily.rename(columns={'State Initial': 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of columns\n",
    "cols = list(states_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the column to head of list using index, pop and insert\n",
    "for col in ['date','Geography', 'State']:\n",
    "    cols.insert(0, cols.pop(cols.index(col)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ix to reorder\n",
    "states_daily = states_daily.reindex(columns =cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "#Change Dir\n",
    "states_daily.to_csv(f'{BOX_PATH}/Data/Combined/states_all.csv', index=False)\n",
    "\n",
    "#Actions\n",
    "#Change Dir\n",
    "ta_total.to_csv(f'{box_dir}/Actions/historical/state_actions_historical.csv', index=False)\n",
    "l.to_csv(f'{box_dir}/Actions/current/recent_actions.csv', index=False)\n",
    "\n",
    "#Projections\n",
    "#Change Dir\n",
    "projections.to_csv(f'{BOX_PATH}/Data/Projections/projections_state.csv', index=False)\n",
    "\n",
    "#Demographics\n",
    "#Change Dir\n",
    "full_state_static.to_csv(f'{BOX_PATH}/Data/Static/State/states_2018_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l#.to_csv(f'{box_dir}/Actions/current/recent_actions_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "642px",
    "width": "434px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
